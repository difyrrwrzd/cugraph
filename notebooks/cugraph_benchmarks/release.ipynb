{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Benchmarking\n",
    "\n",
    "With every release, RAPIDS publishes a release slide deck that includes the current performance state of cuGraph. \n",
    "This notebook run all the various algorithms to compuite the performance gain.  \n",
    "\n",
    "### Algorithms\n",
    "| Algorithm  |\n",
    "| ------------------------|\n",
    "| BFS |\n",
    "| SSSP |\n",
    "| PageRank |\n",
    "| WCC |\n",
    "| Betweenness Centrality (vertex) |\n",
    "| Louvain |\n",
    "| Triangle Counting |\n",
    "\n",
    "### Test Data\n",
    "\n",
    "| File Name              | Num of Vertices | Num of Edges |\n",
    "| ---------------------- | --------------: | -----------: |\n",
    "| preferentialAttachment |         100,000 |      999,970 |\n",
    "| dblp-2010              |         326,186 |    1,615,400 |\n",
    "| coPapersCiteseer       |         434,102 |   32,073,440 |\n",
    "| as-Skitter             |       1,696,415 |   22,190,596 |\n",
    "\n",
    "\n",
    "Notebook Credits\n",
    "\n",
    "    Original Authors: Bradley Rees\n",
    "    Last Edit: 08/17/2020\n",
    "    \n",
    "RAPIDS Versions: 0.15\n",
    "\n",
    "Test Hardware\n",
    "    GV100 32G, CUDA 10.2\n",
    "    Intel(R) Core(TM) CPU i7-7800X @ 3.50GHz\n",
    "    32GB system memory\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing \n",
    "What is not timed:  Reading the data</p>\n",
    "What is timmed: (1) creating a Graph, (2) running the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cudf\n",
    "\n",
    "# NetworkX libraries\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import matplotlib\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install matplotlib')\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test File\n",
    "data = {\n",
    "    'preferentialAttachment' : '../data/preferentialAttachment.csv',\n",
    "    'dblp'                   : '../data/dblp.csv',\n",
    "    'coPapersCiteseer'       : '../data/coPapersCiteseer.csv',\n",
    "    'as-Skitter'             : '../data/as-Skitter.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "The data is read in once once and used for both cuGraph and NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(datafile):\n",
    "    print (f\"reading {v}\")\n",
    "    _gdf = cudf.read_csv(datafile, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'] )\n",
    "    return _gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX\n",
    "def create_nx_graph(_df):\n",
    "    t1 = time.time()\n",
    "\n",
    "    _gnx = nx.from_pandas_edgelist(_df, source='src', target='dst', edge_attr=None, create_using=nx.DiGraph)\n",
    "\n",
    "    t2 = time.time() - t1\n",
    "\n",
    "    return _gnx, t2\n",
    "\n",
    "# cuGraph - force CSR creation\n",
    "def create_cu_graph(_df):\n",
    "    t1 = time.time()\n",
    "\n",
    "    _g = cugraph.DiGraph()\n",
    "    _g.from_cudf_edgelist(_df, source='src', destination='dst', renumber=False)\n",
    "    _ = _g.view_adj_list()\n",
    "    t2 = time.time() - t1\n",
    "\n",
    "    return _g, t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bfs(_G):\n",
    "    t1 = time.time()\n",
    "    _ = nx.bfs_edges(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs(_G):\n",
    "    t1 = time.time()\n",
    "    _ = cugraph.bfs(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_sssp(_G):\n",
    "    t1 = time.time()\n",
    "    _ = nx.shortest_path(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp(_G):\n",
    "    t1 = time.time()\n",
    "    _ = cugraph.sssp(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_pagerank(_G):\n",
    "    t1 = time.time()\n",
    "    _ = nx.pagerank(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_pagerank(_G):\n",
    "    t1 = time.time()   \n",
    "    _ = cugraph.pagerank(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_wcc(_G):\n",
    "    t1 = time.time()\n",
    "    _ = nx.weakly_connected_components(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_wcc(_G):\n",
    "    t1 = time.time()\n",
    "    _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality (vertex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bc(_G):\n",
    "    t1 = time.time()\n",
    "    _ = nx.betweenness_centrality(_G, k=100)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc(_G):\n",
    "    t1 = time.time()\n",
    "    _ = cugraph.betweenness_centrality(_G, k=100)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_louvain(_G):\n",
    "    t1 = time.time()\n",
    "    ug = _G.to_undirected()\n",
    "    \n",
    "    parts = community.best_partition(ug)\n",
    "    \n",
    "    # Calculating modularity scores for comparison \n",
    "    _ = community.modularity(parts, ug)  \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain(_G):\n",
    "    t1 = time.time()\n",
    "    _,_ = cugraph.louvain(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_tc(_G):\n",
    "    t1 = time.time()\n",
    "    nx_count = nx.triangles(_G)\n",
    "    \n",
    "    # To get the number of triangles, we would need to loop through the array and add up each count\n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value    \n",
    "    \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc(_G):\n",
    "    t1 = time.time()\n",
    "    _ = cugraph.triangles(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datasets\n",
    "num_datasets = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ../data/preferentialAttachment.csv\n",
      "reading ../data/preferentialAttachment.csv\n",
      "\tdata in gdf 999970 and data in pandas 999970\n",
      "\tcugraph Size 999970\n",
      "\tcugraph Order 100000\n",
      "\tcreated Gx in 2.2733235359191895 seconds vs Cu in 0.0037124156951904297\n",
      "\tBFS\n",
      "\tSSSP\n",
      "\tPageRank\n",
      "\tWCC\n",
      "\tBC\n",
      "\tLouvain\n"
     ]
    }
   ],
   "source": [
    "# arrays to capture performance gains\n",
    "names = []\n",
    "time_create_cu = []\n",
    "time_create_nx = []\n",
    "\n",
    "# Two dimension data\n",
    "time_algo_cu = []       # will be two dimensional\n",
    "time_algo_nx = []       # will be two dimensional\n",
    "perf = []\n",
    "\n",
    "# do a simple pass just to get all the libraries initiallized\n",
    "v = '../data/preferentialAttachment.csv'\n",
    "gdf = read_data(v)\n",
    "#trapids = cugraph_call(M)\n",
    "del gdf\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "i = 0\n",
    "for k,v in data.items():\n",
    "    time_algo_cu.append([])\n",
    "    time_algo_nx.append([])\n",
    "    perf.append([])\n",
    "    \n",
    "    # Saved the file Name\n",
    "    names.append(k)\n",
    "\n",
    "    # read data\n",
    "    gdf = read_data(v)\n",
    "    pdf = gdf.to_pandas()\n",
    "    print(f\"\\tdata in gdf {len(gdf)} and data in pandas {len(pdf)}\")\n",
    "\n",
    "    # Create the DiGraphs\n",
    "\n",
    "    Gx, tx = create_nx_graph(pdf)\n",
    "    Gc, tc = create_cu_graph(gdf)\n",
    "    \n",
    "    time_create_nx.append(tx)\n",
    "    time_create_cu.append(tc)\n",
    "    \n",
    "    print(f\"\\tcugraph Size {Gc.number_of_edges()}\")\n",
    "    print(f\"\\tcugraph Order {Gc.number_of_vertices()}\")\n",
    "    print(f\"\\tcreated Gx in {tx} seconds vs Cu in {tc}\")\n",
    "    \n",
    "    # BFS\n",
    "    print(\"\\tBFS\")\n",
    "    tx = nx_bfs(Gx)\n",
    "    tc = cu_bfs(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    \n",
    "    # SSSP\n",
    "    print(\"\\tSSSP\")\n",
    "    tx = nx_sssp(Gx)\n",
    "    tc = cu_sssp(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    # PageRank\n",
    "    print(\"\\tPageRank\")    \n",
    "    tx = nx_pagerank(Gx)\n",
    "    tc = cu_pagerank(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    # WCC\n",
    "    print(\"\\tWCC\")\n",
    "    tx = nx_wcc(Gx)\n",
    "    tc = cu_wcc(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    # BC\n",
    "    print(\"\\tBC\")\n",
    "    tx = nx_bc(Gx)\n",
    "    tc = cu_bc(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    # Louvain\n",
    "    print(\"\\tLouvain\")\n",
    "    tx = nx_louvain(Gx)\n",
    "    tc = cu_lovain(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    # TC\n",
    "    print(\"\\tTC\")\n",
    "    tx = nx_tc(Gx)\n",
    "    tc = cu_tc(Gc)\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    i = i + 1\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print results\n",
    "for i in range(num_datasets):\n",
    "    perf[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cugraph_dev",
   "language": "python",
   "name": "cugraph_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
